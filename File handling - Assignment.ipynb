{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb045e53-c8a4-4d54-9f3f-43b3b25fd6ad",
   "metadata": {},
   "source": [
    "# Python File Handling Practice Questions\n",
    "\n",
    "## 1. Beginner Level\n",
    "\n",
    "### 1.1. Line Counter\n",
    "Create a program that reads a text file and counts the number of lines in it.\n",
    "\n",
    "**Requirements:**\n",
    "- Write a function called `count_lines(file_path)` that takes a file path as input and returns the number of lines in the file.\n",
    "- Handle the case where the file does not exist by returning an appropriate error message.\n",
    "- Include a `main()` function that:\n",
    "  - Asks the user for a file path\n",
    "  - Calls your `count_lines()` function\n",
    "  - Displays the result or error message\n",
    "\n",
    "**Example Output:**\n",
    "\n",
    "```\n",
    "Enter file path: sample.txt\n",
    "The file sample.txt contains 15 lines.\n",
    "\n",
    "Enter file path: nonexistent.txt\n",
    "Error: The file nonexistent.txt does not exist.\n",
    "```\n",
    "\n",
    "### 1.2. User Input Writer\n",
    "Create a program that takes input from a user and writes it to a file.\n",
    "\n",
    "**Requirements:**\n",
    "- Ask the user for a filename to write to\n",
    "- Ask the user for a series of lines to write to the file\n",
    "- The user should be able to indicate when they are done entering text (e.g., by entering an empty line or typing 'DONE')\n",
    "- Write all the input lines to the specified file\n",
    "- At the end, display a confirmation message showing how many lines were written\n",
    "\n",
    "**Example Output:**\n",
    "\n",
    "```\n",
    "Enter file name: my_notes.txt\n",
    "Enter text to write to the file. Type 'DONE' on a new line when finished.\n",
    "Line 1: This is my first note.\n",
    "Line 2: Python file handling is interesting.\n",
    "Line 3: I'm learning how to write to files.\n",
    "Line 4: DONE\n",
    "\n",
    "Successfully wrote 3 lines to my_notes.txt.\n",
    "```\n",
    "\n",
    "### 1.3. File Appender\n",
    "Create a program that appends a new line of text to an existing file.\n",
    "\n",
    "**Requirements:**\n",
    "- Write a function called `append_to_file(file_path, text)` that appends the given text to the specified file\n",
    "- If the file doesn't exist, create it\n",
    "- Include a `main()` function that:\n",
    "  - Asks the user for a file path\n",
    "  - Asks the user for text to append\n",
    "  - Calls your `append_to_file()` function\n",
    "  - Gives feedback on the operation's success\n",
    "- Add a timestamp at the beginning of each appended line in the format `[YYYY-MM-DD HH:MM:SS]`\n",
    "\n",
    "**Example Output:**\n",
    "\n",
    "```\n",
    "Enter file path: log.txt\n",
    "Enter text to append: User logged in\n",
    "Successfully appended to log.txt.\n",
    "\n",
    "Contents of log.txt:\n",
    "[2023-05-10 14:32:45] User logged in\n",
    "```\n",
    "\n",
    "### 1.4. Number Calculator\n",
    "Create a program that reads numbers from a file and performs calculations on them.\n",
    "\n",
    "**Requirements:**\n",
    "- The input file should contain one number per line\n",
    "- Write a function called `process_numbers(file_path)` that:\n",
    "  - Reads all numbers from the file\n",
    "  - Calculates the sum, average, minimum, and maximum values\n",
    "  - Returns these statistics as a dictionary\n",
    "- Include a `main()` function that:\n",
    "  - Asks the user for a file path\n",
    "  - Calls your `process_numbers()` function\n",
    "  - Displays the calculated statistics\n",
    "- Handle potential errors such as missing files or non-numeric content\n",
    "\n",
    "**Example Input File (numbers.txt):**\n",
    "\n",
    "```\n",
    "10\n",
    "25\n",
    "15\n",
    "30\n",
    "5\n",
    "```\n",
    "\n",
    "**Example Output:**\n",
    "\n",
    "```\n",
    "Enter file path: numbers.txt\n",
    "Statistics:\n",
    "- Sum: 85\n",
    "- Average: 17.0\n",
    "- Minimum: 5\n",
    "- Maximum: 30\n",
    "- Count: 5\n",
    "```\n",
    "\n",
    "### 1.5. File Existence Checker\n",
    "Create a utility function that checks if a file exists before attempting to open it.\n",
    "\n",
    "**Requirements:**\n",
    "- Write a function called `safe_open_file(file_path, mode)` that:\n",
    "  - Checks if the file exists when opening in read mode\n",
    "  - Returns a file object if the file can be opened\n",
    "  - Returns None and prints an appropriate error message if the file cannot be opened\n",
    "- Create a simple demonstration program that uses this function to:\n",
    "  - Read and display the contents of a file that exists\n",
    "  - Attempt to read a file that doesn't exist\n",
    "  - Create and write to a new file\n",
    "\n",
    "**Example Output:**\n",
    "\n",
    "```\n",
    "Enter a file to read: existing.txt\n",
    "File contents:\n",
    "This is the content of the existing file.\n",
    "\n",
    "Enter a file to read: nonexistent.txt\n",
    "Error: The file 'nonexistent.txt' does not exist.\n",
    "\n",
    "Enter a file to create: new_file.txt\n",
    "Enter text to write: This is a new file created by my program.\n",
    "Successfully wrote to new_file.txt.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a006a5-0f46-429d-8658-7f22ae2ec23c",
   "metadata": {},
   "source": [
    "## 2. Intermediate Level\n",
    "\n",
    "### 2.1. CSV Student Grade Processor\n",
    "Create a program that processes student grades stored in a CSV file and generates statistics.\n",
    "\n",
    "**Requirements:**\n",
    "- The CSV file format should be: `student_id,name,assignment1,assignment2,midterm,final`\n",
    "- Example row: `1001,John Smith,85,92,78,88`\n",
    "- Write functions to:\n",
    "  - Read the CSV file into a suitable data structure\n",
    "  - Calculate each student's final grade (weighted average: assignments 40%, midterm 25%, final 35%)\n",
    "  - Determine letter grades based on a standard scale (A: 90-100, B: 80-89, C: 70-79, D: 60-69, F: below 60)\n",
    "  - Calculate class statistics (average, median, highest, and lowest grades)\n",
    "  - Generate a report showing each student's final numerical grade and letter grade\n",
    "  - Save the report to a new CSV file\n",
    "- Include error handling for potential CSV formatting issues\n",
    "\n",
    "**Sample Input File (student_grades.csv):**\n",
    "\n",
    "```\n",
    "student_id,name,assignment1,assignment2,midterm,final\n",
    "1001,John Smith,85,92,78,88\n",
    "1002,Maria Garcia,95,88,91,85\n",
    "1003,Ahmed Khan,75,80,65,72\n",
    "1004,Lisa Chen,92,95,88,94\n",
    "```\n",
    "\n",
    "**Example Output:**\n",
    "\n",
    "```\n",
    "Enter grades CSV file: student_grades.csv\n",
    "Enter output file name: grade_report.csv\n",
    "\n",
    "Processing complete! Results saved to grade_report.csv\n",
    "\n",
    "Class Statistics:\n",
    "- Average Grade: 84.6\n",
    "- Median Grade: 83.9\n",
    "- Highest Grade: 92.3 (Lisa Chen)\n",
    "- Lowest Grade: 73.4 (Ahmed Khan)\n",
    "\n",
    "Grade Distribution:\n",
    "- A: 1 students\n",
    "- B: 2 students\n",
    "- C: 1 students\n",
    "- D: 0 students\n",
    "- F: 0 students\n",
    "```\n",
    "\n",
    "### 2.2. Binary File Handler\n",
    "Create a program that reads and writes binary data like images.\n",
    "\n",
    "**Requirements:**\n",
    "- Write a function to copy a binary file (e.g., an image) from one location to another\n",
    "- Add functionality to:\n",
    "  - Display basic file metadata (size, creation date, modification date)\n",
    "  - Create a backup by appending a timestamp to the filename\n",
    "  - Split a large binary file into smaller chunks of a specified size\n",
    "  - Merge previously split chunks back into a complete file\n",
    "- Include proper error handling for cases like insufficient disk space or permission issues\n",
    "\n",
    "**Example Output:**\n",
    "\n",
    "```\n",
    "Enter operation (copy/metadata/backup/split/merge): metadata\n",
    "Enter file path: sample.jpg\n",
    "\n",
    "File Metadata:\n",
    "- Name: sample.jpg\n",
    "- Size: 2,457,890 bytes (2.34 MB)\n",
    "- Created: 2023-05-10 15:30:45\n",
    "- Modified: 2023-05-15 09:12:33\n",
    "- File type: JPEG image\n",
    "\n",
    "Enter operation (copy/metadata/backup/split/merge): split\n",
    "Enter file path: large_video.mp4\n",
    "Enter chunk size in MB: 50\n",
    "Splitting file...\n",
    "Created 12 chunks in directory 'large_video_chunks/':\n",
    "- large_video_part_1.bin (50 MB)\n",
    "- large_video_part_2.bin (50 MB)\n",
    "...\n",
    "- large_video_part_12.bin (18 MB)\n",
    "```\n",
    "\n",
    "### 2.3. Directory File Searcher\n",
    "Create a program that searches for files with specific extensions in a directory and its subdirectories.\n",
    "\n",
    "**Requirements:**\n",
    "- Write a function `find_files(directory, extensions, recursive=True)` that:\n",
    "  - Searches the specified directory for files with the given extensions\n",
    "  - Can search recursively through subdirectories if the recursive parameter is True\n",
    "  - Returns a list of matching files with their full paths\n",
    "- Include options to:\n",
    "  - Sort results by name, size, or modification date\n",
    "  - Filter files by size or modification date\n",
    "  - Display results in a formatted table\n",
    "  - Save results to a text or CSV file\n",
    "- Implement proper error handling for invalid directories and permission issues\n",
    "\n",
    "**Example Output:**\n",
    "\n",
    "```\n",
    "Enter directory to search: /home/user/documents\n",
    "Enter file extensions (comma-separated): .pdf,.docx,.txt\n",
    "Search subdirectories? (y/n): y\n",
    "Sort by (name/size/date): date\n",
    "Minimum file size in KB (0 for no minimum): 100\n",
    "\n",
    "Found 15 matching files:\n",
    "+-----+-------------------------+------------+-----------------+\n",
    "| No. | Filename                | Size (KB)  | Last Modified   |\n",
    "+-----+-------------------------+------------+-----------------+\n",
    "| 1   | report_final.docx       | 2,456      | 2023-05-15 13:45|\n",
    "| 2   | presentation.pdf        | 3,872      | 2023-05-14 09:12|\n",
    "...\n",
    "+-----+-------------------------+------------+-----------------+\n",
    "\n",
    "Save results to file? (y/n): y\n",
    "Enter output filename: search_results.csv\n",
    "Results saved to search_results.csv\n",
    "```\n",
    "\n",
    "### 2.4. Object Serialization System\n",
    "Create a program that uses the `pickle` module to save and load Python objects.\n",
    "\n",
    "**Requirements:**\n",
    "- Create a `Student` class with attributes for name, ID, courses, and grades\n",
    "- Implement methods to add courses, record grades, and calculate GPA\n",
    "- Write functions to:\n",
    "  - Save a collection of Student objects to a pickle file\n",
    "  - Load Student objects from a pickle file\n",
    "  - Search for students by name or ID\n",
    "  - Generate reports on student performance\n",
    "- Create a simple command-line interface to interact with the system\n",
    "- Include versioning in your serialization to handle changes to the class structure\n",
    "\n",
    "**Example Output:**\n",
    "\n",
    "```\n",
    "Student Management System\n",
    "------------------------\n",
    "1. Add new student\n",
    "2. Record grades\n",
    "3. Search students\n",
    "4. Generate reports\n",
    "5. Save database\n",
    "6. Load database\n",
    "7. Exit\n",
    "\n",
    "Enter choice: 1\n",
    "Enter student name: Jane Lee\n",
    "Enter student ID: S12345\n",
    "Student added successfully.\n",
    "\n",
    "Enter choice: 2\n",
    "Enter student ID: S12345\n",
    "Enter course name: Computer Science 101\n",
    "Enter grade (0-100): 95\n",
    "Grade recorded successfully.\n",
    "\n",
    "Enter choice: 5\n",
    "Saving database to students.pkl...\n",
    "Database saved successfully.\n",
    "\n",
    "Enter choice: 6\n",
    "Loading database from students.pkl...\n",
    "Loaded 5 student records.\n",
    "```\n",
    "\n",
    "### 2.5. Context Manager for File Processing\n",
    "Implement file operations using the `with` statement and create custom context managers.\n",
    "\n",
    "**Requirements:**\n",
    "- Implement a function that uses the `with` statement to safely process a file\n",
    "- Create a custom context manager called `TempFileManager` that:\n",
    "  - Creates a temporary file for writing\n",
    "  - Automatically deletes the file when the context is exited, unless the operation was successful\n",
    "  - Provides methods to write to and read from the temporary file\n",
    "- Create another context manager called `BackupFileManager` that:\n",
    "  - Creates a backup of a file before modifying it\n",
    "  - Restores the backup if an exception occurs during processing\n",
    "  - Removes the backup if processing completes successfully\n",
    "- Demonstrate the use of both context managers with examples\n",
    "\n",
    "**Example Usage:**\n",
    "\n",
    "```python\n",
    "# Example usage of BackupFileManager\n",
    "with BackupFileManager('important_data.txt') as file:\n",
    "    content = file.read()\n",
    "    # Modify content\n",
    "    new_content = content.replace('old value', 'new value')\n",
    "    file.write(new_content)\n",
    "    # If an exception occurs here, the file will be restored from backup\n",
    "print(\"File was modified successfully.\")\n",
    "```\n",
    "\n",
    "**Example Output:**\n",
    "\n",
    "```\n",
    "Using TempFileManager:\n",
    "Created temporary file: /tmp/temp_file_8273.txt\n",
    "Writing data to temporary file...\n",
    "Reading data from temporary file...\n",
    "Operation completed successfully.\n",
    "Temporary file has been retained at: /tmp/temp_file_8273.txt\n",
    "\n",
    "Using BackupFileManager:\n",
    "Created backup of config.ini at config.ini.bak\n",
    "Modifying file...\n",
    "Modification successful. Backup file deleted.\n",
    "\n",
    "Simulating error with BackupFileManager:\n",
    "Created backup of config.ini at config.ini.bak\n",
    "Attempting risky operation...\n",
    "Error occurred: division by zero\n",
    "File has been restored from backup.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6920c0-32b3-4f8d-a515-47aa54b7f2c5",
   "metadata": {},
   "source": [
    "## 3. Advanced Level\n",
    "\n",
    "### 3.1. Concurrent File Processor\n",
    "Create a program that uses multithreading or multiprocessing to process multiple files simultaneously.\n",
    "\n",
    "**Requirements:**\n",
    "- Implement a function that performs a CPU-intensive operation on file contents (e.g., counting word frequencies, performing text analysis)\n",
    "- Write two versions of a batch processor:\n",
    "  - One using `threading` for I/O-bound operations\n",
    "  - One using `multiprocessing` for CPU-bound operations\n",
    "- The processor should:\n",
    "  - Accept a directory of text files as input\n",
    "  - Process each file to extract statistics or transform the content\n",
    "  - Write results to an output directory\n",
    "  - Include progress tracking and reporting\n",
    "  - Handle errors gracefully without stopping the entire batch\n",
    "- Include performance measurements to compare single-threaded vs. concurrent approaches\n",
    "\n",
    "**Example Output:**\n",
    "```\n",
    "Enter directory with text files: /data/articles\n",
    "Enter output directory: /data/results\n",
    "Select processing mode:\n",
    "1. Single-threaded\n",
    "2. Multi-threaded\n",
    "3. Multi-process\n",
    "Enter choice: 3\n",
    "\n",
    "Starting multi-process processing with 8 worker processes...\n",
    "Processing 247 files...\n",
    "[====================] 100% Complete\n",
    "Time elapsed: 35.2 seconds\n",
    "\n",
    "Performance comparison:\n",
    "- Single-threaded: 142.7 seconds\n",
    "- Multi-threaded: 138.5 seconds\n",
    "- Multi-process: 35.2 seconds\n",
    "\n",
    "Results summary:\n",
    "- Total words processed: 2,456,789\n",
    "- Average words per file: 9,946\n",
    "- Most frequent words: [{'word': 'the', 'count': 143567}, {'word': 'and', 'count': 92845}, ...]\n",
    "```\n",
    "\n",
    "### 3.2. Memory-Mapped File Processor\n",
    "Implement a solution using `mmap` to efficiently process very large files.\n",
    "\n",
    "**Requirements:**\n",
    "- Create a program that can search and manipulate files that are too large to fit in memory\n",
    "- Implement functions to:\n",
    "  - Find all occurrences of a pattern in a large file without loading the entire file\n",
    "  - Replace text in-place without creating a copy of the file\n",
    "  - Extract sections of the file based on start/end markers\n",
    "  - Generate statistics on the file content using a sliding window approach\n",
    "- Compare the performance with traditional file I/O methods\n",
    "- Include proper error handling for memory mapping issues\n",
    "\n",
    "**Example Output:**\n",
    "```\n",
    "Enter large file path: huge_log.txt (5.7 GB)\n",
    "Enter operation (search/replace/extract/stats): search\n",
    "Enter search pattern: ERROR:\n",
    "Using memory-mapped approach...\n",
    "\n",
    "Found 1,275 matches:\n",
    "Position 2456789: ERROR: Database connection failed\n",
    "Position 3561928: ERROR: Invalid input parameter\n",
    "...\n",
    "\n",
    "Time taken: 12.3 seconds\n",
    "Estimated time with traditional I/O: 87.5 seconds\n",
    "Memory usage: 24.5 MB\n",
    "```\n",
    "\n",
    "### 3.3. Streaming Data Processor\n",
    "Create a program that processes a large file in chunks to minimize memory usage.\n",
    "\n",
    "**Requirements:**\n",
    "- Implement functions to process different types of large files in a streaming fashion:\n",
    "  - Large CSV files (processing one row at a time)\n",
    "  - Large JSON files (using a streaming JSON parser)\n",
    "  - Large XML files (using an incremental parser)\n",
    "- The program should:\n",
    "  - Allow filtering records based on specified criteria\n",
    "  - Transform data as it's being read\n",
    "  - Generate aggregated statistics\n",
    "  - Write filtered/transformed output to new files\n",
    "- Include memory usage monitoring to demonstrate the efficiency of the streaming approach\n",
    "- Support progress reporting for long-running operations\n",
    "\n",
    "**Example Output:**\n",
    "```\n",
    "Enter file to process: large_dataset.csv (3.2 GB)\n",
    "Select file type:\n",
    "1. CSV\n",
    "2. JSON\n",
    "3. XML\n",
    "Enter choice: 1\n",
    "\n",
    "Enter filter criteria (Python expression using 'row' variable): int(row['age']) > 30 and row['country'] == 'Canada'\n",
    "Enter output file (leave empty to only generate statistics): filtered_dataset.csv\n",
    "\n",
    "Processing in streaming mode...\n",
    "[====================] 100% Complete\n",
    "Processed 50,000,000 records in 87.5 seconds\n",
    "Found 2,345,678 matching records\n",
    "Memory usage remained under 25 MB throughout processing\n",
    "\n",
    "Statistics:\n",
    "- Average age of matching records: 42.7\n",
    "- Most common city: Toronto (123,456 records)\n",
    "- Gender distribution: 54% Female, 46% Male\n",
    "- Income quartiles: [45000, 65000, 85000, 380000]\n",
    "\n",
    "Output file created successfully.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b28c4c-2024-423f-a3ed-06bc14babb1e",
   "metadata": {},
   "source": [
    "### 3.4. File Watcher and Event Handler\n",
    "Create a program that monitors a directory for file changes and performs actions when changes are detected.\n",
    "\n",
    "**Requirements:**\n",
    "- Use the `watchdog` library or similar to monitor a directory for changes\n",
    "- Implement event handlers for different types of events:\n",
    "  - File creation\n",
    "  - File modification\n",
    "  - File deletion\n",
    "  - File movement/renaming\n",
    "- Configure different actions for different file types:\n",
    "  - For image files: generate thumbnails when created or modified\n",
    "  - For log files: parse new entries and generate alerts for errors\n",
    "  - For data files: update a database or perform calculations\n",
    "- Include options for:\n",
    "  - Recursive monitoring of subdirectories\n",
    "  - Filtering which files to monitor based on patterns\n",
    "  - Throttling events to prevent excessive processing\n",
    "  - Logging all activities to a history file\n",
    "\n",
    "**Example Output:**\n",
    "```\n",
    "Enter directory to watch: /var/www/uploads\n",
    "Watch subdirectories? (y/n): y\n",
    "Enter file patterns to monitor (comma-separated, empty for all): *.jpg,*.png,*.log\n",
    "Starting file watcher...\n",
    "\n",
    "[2023-05-17 14:32:45] EVENT: Created - /var/www/uploads/vacation.jpg\n",
    "   ACTION: Generated thumbnail at /var/www/uploads/thumbnails/vacation_thumb.jpg\n",
    "\n",
    "[2023-05-17 14:33:12] EVENT: Modified - /var/www/uploads/logs/server.log\n",
    "   ACTION: Parsed 15 new log entries\n",
    "   ALERT: Found 2 critical errors, email notification sent to admin\n",
    "\n",
    "[2023-05-17 14:35:28] EVENT: Deleted - /var/www/uploads/temp/test.png\n",
    "   ACTION: Removed corresponding thumbnail\n",
    "\n",
    "[2023-05-17 14:36:10] EVENT: Moved - /var/www/uploads/doc1.pdf -> /var/www/uploads/archive/doc1.pdf\n",
    "   ACTION: Updated file index database\n",
    "\n",
    "Press Ctrl+C to stop watching...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6800d9-f2cb-4000-8d36-6f1e8b23146e",
   "metadata": {},
   "source": [
    "### 3.5. Encrypted File System\n",
    "Create a secure file storage system that encrypts files and manages access through authentication.\n",
    "\n",
    "**Requirements:**\n",
    "- Implement a class-based system that provides:\n",
    "  - User registration and authentication\n",
    "  - File encryption using strong encryption (e.g., AES)\n",
    "  - Secure key management derived from user passwords\n",
    "  - Directory structure for organizing encrypted files\n",
    "- Include functionality for:\n",
    "  - Uploading and encrypting files\n",
    "  - Downloading and decrypting files\n",
    "  - Sharing files with other users\n",
    "  - Setting and enforcing access permissions\n",
    "  - Key rotation and password changes\n",
    "- Implement proper security measures:\n",
    "  - Password hashing and salting\n",
    "  - Protection against brute-force attacks\n",
    "  - Secure deletion of temporary decrypted files\n",
    "  - Audit logging of all security-relevant events\n",
    "\n",
    "**Example Output:**\n",
    "\n",
    "```\n",
    "Secure File System\n",
    "-----------------\n",
    "1. Register\n",
    "2. Login\n",
    "3. Exit\n",
    "\n",
    "Enter choice: 1\n",
    "Enter username: alice\n",
    "Enter password: ********\n",
    "Confirm password: ********\n",
    "Registration successful!\n",
    "\n",
    "Enter choice: 2\n",
    "Enter username: alice\n",
    "Enter password: ********\n",
    "Login successful!\n",
    "\n",
    "Secure File System - User: alice\n",
    "-------------------------------\n",
    "1. Upload file\n",
    "2. Download file\n",
    "3. List files\n",
    "4. Share file\n",
    "5. Change password\n",
    "6. Logout\n",
    "\n",
    "Enter choice: 1\n",
    "Enter file path: confidential_report.docx\n",
    "Enter optional description: Q2 financial projections\n",
    "Encrypting file...\n",
    "File uploaded and encrypted successfully.\n",
    "Encryption key securely stored.\n",
    "\n",
    "Enter choice: 3\n",
    "Your files:\n",
    "+-----+-------------------------+------------+-----------------+----------+\n",
    "| No. | Filename                | Size       | Uploaded        | Shared   |\n",
    "+-----+-------------------------+------------+-----------------+----------+\n",
    "| 1   | confidential_report.docx| 2.4 MB     | 2023-05-17 15:30| No       |\n",
    "+-----+-------------------------+------------+-----------------+----------+\n",
    "\n",
    "Enter choice: 4\n",
    "Enter file number: 1\n",
    "Enter username to share with: bob\n",
    "Enter permission (read/write): read\n",
    "Set expiration date? (y/n): y\n",
    "Enter expiration date (YYYY-MM-DD): 2023-06-17\n",
    "File shared successfully with bob (read access until 2023-06-17).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dfd586-b797-4ade-bd6e-4a86720f48b8",
   "metadata": {},
   "source": [
    "## 4. Expert Level\n",
    "\n",
    "### 4.1. Distributed File Processor\n",
    "Create a distributed system for processing large files across multiple machines.\n",
    "\n",
    "**Requirements:**\n",
    "- Design a master-worker architecture where:\n",
    "  - A master node divides large processing tasks into smaller chunks\n",
    "  - Worker nodes process individual chunks in parallel\n",
    "  - Results are collected and combined by the master\n",
    "- Implement networking using `socket` or higher-level libraries like `ZeroMQ` or `gRPC`\n",
    "- The system should:\n",
    "  - Handle task distribution and load balancing\n",
    "  - Provide fault tolerance for worker failures\n",
    "  - Support worker discovery and registration\n",
    "  - Include monitoring and status reporting\n",
    "- Include functionality for:\n",
    "  - Batch processing multiple files\n",
    "  - Different processing algorithms selectable at runtime\n",
    "  - Checkpointing and resuming interrupted tasks\n",
    "  - Estimating completion time based on worker performance\n",
    "\n",
    "**Example Output:**\n",
    "\n",
    "```\n",
    "Distributed File Processor - Master Node\n",
    "---------------------------------------\n",
    "Starting master node on 192.168.1.100:5000\n",
    "Waiting for worker nodes to connect...\n",
    "\n",
    "Worker node connected: 192.168.1.101:6001\n",
    "Worker node connected: 192.168.1.102:6001\n",
    "Worker node connected: 192.168.1.103:6001\n",
    "\n",
    "Enter task type:\n",
    "1. Word frequency analysis\n",
    "2. Pattern matching\n",
    "3. Data transformation\n",
    "4. Custom script\n",
    "Enter choice: 1\n",
    "\n",
    "Enter directory or file pattern: /data/corpus/*.txt\n",
    "Found 250 files totaling 4.8 GB\n",
    "Distributing tasks to 3 workers...\n",
    "\n",
    "Progress:\n",
    "[====================] 100% Complete\n",
    "Time elapsed: 45.2 minutes\n",
    "Estimated time with single machine: 2.1 hours\n",
    "\n",
    "Results:\n",
    "- Processed 4.8 GB of text across 250 files\n",
    "- Total words: 825,432,156\n",
    "- Unique words: 2,145,687\n",
    "- Top 10 words: [{'word': 'the', 'count': 45123456}, ...]\n",
    "\n",
    "Save detailed results to file? (y/n): y\n",
    "Enter output file path: word_frequency_analysis.json\n",
    "Results saved successfully.\n",
    "```\n",
    "\n",
    "### 4.2. Virtual File System\n",
    "Implement a virtual file system that provides a unified interface to multiple storage backends.\n",
    "\n",
    "**Requirements:**\n",
    "- Create an abstraction layer that allows accessing different storage systems through a common API:\n",
    "  - Local file system\n",
    "  - Remote FTP/SFTP servers\n",
    "  - Cloud storage (S3, Google Cloud Storage, etc.)\n",
    "  - Database storage (storing files in a database)\n",
    "- Implement a class hierarchy with:\n",
    "  - Abstract base classes defining the interface\n",
    "  - Concrete implementations for each storage backend\n",
    "  - Factory methods for creating appropriate handlers\n",
    "- The API should support:\n",
    "  - Basic CRUD operations (create, read, update, delete)\n",
    "  - Directory operations (list, create, delete)\n",
    "  - File metadata operations\n",
    "  - Searching and filtering\n",
    "  - Transactions and atomic operations when possible\n",
    "- Include advanced features:\n",
    "  - Caching frequently accessed files\n",
    "  - Automatic synchronization between backends\n",
    "  - Handling network interruptions and retries\n",
    "  - Migration between storage backends\n",
    "\n",
    "**Example Usage:**\n",
    "\n",
    "```python\n",
    "# Example usage of the virtual file system\n",
    "from virtual_fs import VirtualFileSystem, StorageType\n",
    "\n",
    "# Initialize with multiple backends\n",
    "vfs = VirtualFileSystem()\n",
    "vfs.add_storage('local', StorageType.LOCAL, root_path='/data/local')\n",
    "vfs.add_storage('remote', StorageType.SFTP, hostname='example.com', \n",
    "                username='user', password='pass', root_path='/data')\n",
    "vfs.add_storage('cloud', StorageType.S3, bucket='my-bucket', \n",
    "                access_key='KEY', secret_key='SECRET')\n",
    "\n",
    "# Operations work the same regardless of backend\n",
    "vfs.create_directory('local:/projects/new_project')\n",
    "vfs.write_file('local:/projects/new_project/readme.txt', 'This is a new project')\n",
    "vfs.copy('local:/projects/new_project', 'cloud:/backups/projects/')\n",
    "vfs.move('remote:/old_data.csv', 'local:/archive/data.csv')\n",
    "\n",
    "# Search across all storage backends\n",
    "results = vfs.find('**/*.log', modified_after='2023-01-01')\n",
    "```\n",
    "\n",
    "**Example Output:**\n",
    "\n",
    "```\n",
    "Virtual File System\n",
    "-----------------\n",
    "1. Configure storage backends\n",
    "2. File operations\n",
    "3. Directory operations\n",
    "4. Search files\n",
    "5. Synchronization\n",
    "6. Exit\n",
    "\n",
    "Enter choice: 1\n",
    "Available storage types:\n",
    "1. Local filesystem\n",
    "2. SFTP server\n",
    "3. Amazon S3\n",
    "4. Google Cloud Storage\n",
    "5. Database (PostgreSQL)\n",
    "Enter choice: 3\n",
    "Enter storage name: cloud_backup\n",
    "Enter bucket name: my-backup-bucket\n",
    "Enter AWS region: us-west-2\n",
    "Enter access key ID: AKIA************\n",
    "Enter secret access key: ****************************************\n",
    "Storage 'cloud_backup' configured successfully.\n",
    "\n",
    "Enter choice: 4\n",
    "Enter search pattern: **/*.pdf\n",
    "Enter storage (leave empty for all): \n",
    "Enter modified after date (YYYY-MM-DD): 2023-05-01\n",
    "\n",
    "Searching...\n",
    "Found 37 files:\n",
    "1. local:/documents/report.pdf (2.4 MB, 2023-05-10)\n",
    "2. local:/archives/old_report.pdf (1.8 MB, 2023-05-12)\n",
    "...\n",
    "15. cloud_backup:/reports/q2_2023.pdf (5.2 MB, 2023-05-15)\n",
    "...\n",
    "\n",
    "Enter choice: 2\n",
    "File operations:\n",
    "1. Create/Write\n",
    "2. Read\n",
    "3. Copy\n",
    "4. Move\n",
    "5. Delete\n",
    "Enter choice: 3\n",
    "Enter source path: local:/documents/report.pdf\n",
    "Enter destination path: cloud_backup:/reports/weekly/report.pdf\n",
    "Copying file...\n",
    "File copied successfully.\n",
    "```\n",
    "\n",
    "### 4.3. File System Transaction Manager\n",
    "Create a system that allows for transactional file operations.\n",
    "\n",
    "**Requirements:**\n",
    "- Implement a transaction manager that:\n",
    "  - Allows grouping multiple file operations into an atomic transaction\n",
    "  - Provides rollback capability if any operation fails\n",
    "  - Maintains a journal of operations for recovery\n",
    "  - Supports nested transactions\n",
    "- Design a simple domain-specific language (DSL) for defining transactions\n",
    "- The system should handle:\n",
    "  - File creation/modification/deletion\n",
    "  - Directory operations\n",
    "  - File permissions and attributes\n",
    "  - Symbolic links and hard links\n",
    "- Include advanced features:\n",
    "  - Transaction isolation levels\n",
    "  - Deadlock detection and prevention\n",
    "  - Performance optimization with bulk operations\n",
    "  - Recovery from system crashes using the journal\n",
    "\n",
    "**Example Usage:**\n",
    "\n",
    "```python\n",
    "# Example usage of file transaction system\n",
    "from fs_transaction import TransactionManager\n",
    "\n",
    "# Start a transaction\n",
    "with TransactionManager() as txn:\n",
    "    # All operations within this block are part of the transaction\n",
    "    txn.create_file('/path/to/config.ini', 'initial content')\n",
    "    txn.create_directory('/path/to/data')\n",
    "    txn.copy_file('/path/to/template.txt', '/path/to/data/file.txt')\n",
    "    \n",
    "    # Nested transaction\n",
    "    with txn.nested() as subtxn:\n",
    "        subtxn.append_to_file('/path/to/log.txt', 'Operation started')\n",
    "        subtxn.modify_file('/path/to/data/file.txt', 'modified content')\n",
    "        # If an exception occurs here, only the subtxn operations are rolled back\n",
    "    \n",
    "    txn.append_to_file('/path/to/log.txt', 'Operation completed')\n",
    "    # If all operations succeed, the entire transaction is committed\n",
    "    # If any operation fails, all operations are rolled back\n",
    "```\n",
    "\n",
    "**Example Output:**\n",
    "\n",
    "```\n",
    "File System Transaction Manager\n",
    "------------------------------\n",
    "1. Interactive transaction\n",
    "2. Run transaction from script\n",
    "3. View journal\n",
    "4. Recover from crash\n",
    "5. Exit\n",
    "\n",
    "Enter choice: 1\n",
    "Starting new transaction (ID: tx_2023051712345)...\n",
    "Enter operations (one per line, empty line to finish):\n",
    "> create_file /etc/app/config.json '{\"debug\": true, \"port\": 8080}'\n",
    "> create_dir /var/app/data\n",
    "> copy_file /etc/app/templates/default.html /var/app/views/index.html\n",
    "> chmod /var/app/data 775\n",
    ">\n",
    "\n",
    "Verifying operations...\n",
    "All operations valid.\n",
    "Execute transaction? (y/n): y\n",
    "\n",
    "Executing transaction tx_2023051712345...\n",
    "[1/4] create_file /etc/app/config.json - SUCCESS\n",
    "[2/4] create_dir /var/app/data - SUCCESS\n",
    "[3/4] copy_file /etc/app/templates/default.html /var/app/views/index.html - FAILED (Permission denied)\n",
    "\n",
    "Error during transaction. Rolling back...\n",
    "[3/3] Deleting directory /var/app/data - SUCCESS\n",
    "[2/3] Deleting file /etc/app/config.json - SUCCESS\n",
    "[1/3] Removing journal entry tx_2023051712345 - SUCCESS\n",
    "\n",
    "Transaction rolled back successfully. No changes were made.\n",
    "```\n",
    "\n",
    "### 4.4. Continuous File Synchronization System\n",
    "Create a robust file synchronization system similar to Dropbox or rsync.\n",
    "\n",
    "**Requirements:**\n",
    "- Implement a system that:\n",
    "  - Continuously monitors directories for changes\n",
    "  - Efficiently synchronizes changes between multiple locations\n",
    "  - Handles conflict resolution when files are modified in multiple locations\n",
    "  - Maintains version history of files\n",
    "- Support different synchronization targets:\n",
    "  - Local directories\n",
    "  - Remote servers via SSH/SFTP\n",
    "  - Cloud storage providers\n",
    "- Include advanced features:\n",
    "  - Bandwidth throttling\n",
    "  - Scheduled synchronization\n",
    "  - File deduplication\n",
    "  - Compression for network transfers\n",
    "  - Selective synchronization (include/exclude patterns)\n",
    "  - Bi-directional and one-way sync options\n",
    "- Provide robust error handling:\n",
    "  - Network interruptions\n",
    "  - Permission issues\n",
    "  - Disk space limitations\n",
    "  - File corruption detection\n",
    "\n",
    "**Example Output:**\n",
    "\n",
    "```\n",
    "Continuous File Synchronization System\n",
    "------------------------------------\n",
    "1. Configure sync locations\n",
    "2. Start monitoring\n",
    "3. View status\n",
    "4. Resolve conflicts\n",
    "5. View history\n",
    "6. Exit\n",
    "\n",
    "Enter choice: 1\n",
    "Enter source directory: /home/user/projects\n",
    "Enter destination: sftp://user@remote.example.com:/backup/projects\n",
    "Enter synchronization mode:\n",
    "1. One-way (source to destination)\n",
    "2. Bi-directional\n",
    "Enter choice: 1\n",
    "Configure advanced options? (y/n): y\n",
    "\n",
    "Advanced Options:\n",
    "1. Include/exclude patterns\n",
    "2. Bandwidth limits\n",
    "3. Compression\n",
    "4. Schedule\n",
    "Enter choice: 1\n",
    "Enter include patterns (comma-separated): *.py,*.js,*.html,*.css\n",
    "Enter exclude patterns (comma-separated): *.pyc,__pycache__,node_modules,*.log\n",
    "Configuration saved successfully.\n",
    "\n",
    "Enter choice: 2\n",
    "Starting file monitoring for configured locations...\n",
    "Initial synchronization in progress...\n",
    "[====================] 100% Complete\n",
    "Synchronized 1,245 files (34.2 MB)\n",
    "Continuous monitoring active. Press Ctrl+C to stop.\n",
    "\n",
    "[2023-05-17 17:32:45] MODIFIED: /home/user/projects/website/index.html (2.3 KB)\n",
    "   Synchronizing to destination...\n",
    "   Successfully synchronized.\n",
    "\n",
    "[2023-05-17 17:35:12] CREATED: /home/user/projects/api/routes.py (5.7 KB)\n",
    "   Synchronizing to destination...\n",
    "   Successfully synchronized.\n",
    "\n",
    "[2023-05-17 17:38:27] NETWORK ERROR: Connection to remote.example.com lost\n",
    "   Queuing changes for later synchronization...\n",
    "   Retrying in 30 seconds...\n",
    "\n",
    "[2023-05-17 17:39:01] CONNECTION RESTORED: remote.example.com\n",
    "   Processing queued changes...\n",
    "   Successfully synchronized 3 pending changes.\n",
    "```\n",
    "\n",
    "### 4.5. Advanced File Compression and Archiving\n",
    "Create a comprehensive system for compressing, archiving, and managing file collections.\n",
    "\n",
    "**Requirements:**\n",
    "- Implement support for multiple compression algorithms and archive formats:\n",
    "  - ZIP, TAR, GZIP, BZIP2, LZMA, 7Z, RAR\n",
    "  - Custom format with optimized compression ratios\n",
    "- Include advanced features:\n",
    "  - Splitting archives into multiple volumes\n",
    "  - Adding/updating/removing files from existing archives\n",
    "  - Creating self-extracting archives\n",
    "  - Creating encrypted archives with password protection\n",
    "  - Repairing damaged archives when possible\n",
    "  - Optimizing compression based on file types\n",
    "- Implement parallel compression using multiple threads\n",
    "- Include comprehensive metadata and indexing:\n",
    "  - Fast searching within archives without full extraction\n",
    "  - Storing and preserving file attributes and permissions\n",
    "  - Creating and verifying checksums\n",
    "- Provide detailed reporting and analytics:\n",
    "  - Compression ratios\n",
    "  - Space savings\n",
    "  - Processing time statistics\n",
    "\n",
    "**Example Output:**\n",
    "\n",
    "```\n",
    "Advanced File Compression and Archiving\n",
    "-------------------------------------\n",
    "1. Create archive\n",
    "2. Extract archive\n",
    "3. Modify archive\n",
    "4. Analyze archive\n",
    "5. Repair archive\n",
    "6. Exit\n",
    "\n",
    "Enter choice: 1\n",
    "Select archive format:\n",
    "1. ZIP\n",
    "2. TAR.GZ\n",
    "3. 7Z\n",
    "4. Custom optimized format\n",
    "Enter choice: 4\n",
    "\n",
    "Enter source directory or file pattern: /home/user/photos/**/*.jpg\n",
    "Found 1,578 files (4.3 GB)\n",
    "Enter destination archive name: photo_collection.cxa\n",
    "Select compression level:\n",
    "1. Fast (lower compression)\n",
    "2. Normal\n",
    "3. Maximum (slower compression)\n",
    "4. Ultra (very slow, best compression)\n",
    "5. Adaptive (based on file types)\n",
    "Enter choice: 5\n",
    "\n",
    "Select additional options:\n",
    "1. Split into volumes\n",
    "2. Add password protection\n",
    "3. Create self-extracting archive\n",
    "4. Add recovery record\n",
    "5. Done with options\n",
    "Enter choice: 2\n",
    "Enter password: ********\n",
    "Confirm password: ********\n",
    "Enter choice: 4\n",
    "Recovery record size (% of archive size): 3\n",
    "Enter choice: 5\n",
    "\n",
    "Creating archive with adaptive compression...\n",
    "Analyzing file types to optimize compression...\n",
    "Using specialized compressor for JPEG files...\n",
    "Parallelizing compression with 8 threads...\n",
    "[====================] 100% Complete\n",
    "\n",
    "Archive created successfully!\n",
    "- Original size: 4.3 GB\n",
    "- Compressed size: 3.8 GB\n",
    "- Compression ratio: 1.13:1 (11.6% space saving)\n",
    "- Processing time: 45.2 seconds\n",
    "- Average speed: 95 MB/s\n",
    "\n",
    "Enter choice: 4\n",
    "Enter archive path: photo_collection.cxa\n",
    "Enter password: ********\n",
    "\n",
    "Archive Analysis:\n",
    "- Format: Custom XA format v2.1\n",
    "- Files: 1,578\n",
    "- Directories: 143\n",
    "- Creation date: 2023-05-17 18:35:45\n",
    "- Compressed size: 3.8 GB\n",
    "- Uncompressed size: 4.3 GB\n",
    "- Compression algorithm: Adaptive multi-algorithm\n",
    "- Recovery record: 3% (116.4 MB)\n",
    "- Encryption: AES-256\n",
    "- Self-extracting: No\n",
    "- Split volumes: No\n",
    "- Archive is intact and verified\n",
    "\n",
    "Content summary by type:\n",
    "- JPEG images: 1,578 files (100%)\n",
    "- Total images by year:\n",
    "  * 2021: 458 files\n",
    "  * 2022: 752 files\n",
    "  * 2023: 368 files\n",
    "\n",
    "Enter search pattern to list matching files: 2023/vacation/**\n",
    "Found 124 matching files in archive:\n",
    "1. 2023/vacation/italy/rome_01.jpg (5.2 MB)\n",
    "2. 2023/vacation/italy/rome_02.jpg (4.8 MB)\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbaeae9-ac26-4243-b7bd-ab1ea6f42d87",
   "metadata": {},
   "source": [
    "## 5. Project Ideas\n",
    "\n",
    "### 5.1. Personal Document Management System\n",
    "Build a complete document management system for personal use.\n",
    "\n",
    "**Features:**\n",
    "- File upload, organization, and tagging\n",
    "- Full-text search using inverted indices\n",
    "- OCR for scanned documents\n",
    "- Version control for document revisions\n",
    "- Document preview and annotation\n",
    "- Metadata extraction (dates, authors, titles)\n",
    "- Web-based interface for access from multiple devices\n",
    "- Automatic categorization using machine learning\n",
    "\n",
    "### 5.2. Log Analysis and Monitoring Tool\n",
    "Create a tool for analyzing and monitoring log files from multiple sources.\n",
    "\n",
    "**Features:**\n",
    "- Real-time log file monitoring\n",
    "- Pattern matching and alert generation\n",
    "- Statistical analysis of log events\n",
    "- Visualization of log data\n",
    "- Aggregation of logs from multiple sources\n",
    "- Anomaly detection\n",
    "- Log rotation and archiving\n",
    "- Report generation\n",
    "\n",
    "### 5.3. File-Based Database System\n",
    "Implement a simple database system that uses files for storage.\n",
    "\n",
    "**Features:**\n",
    "- Support for basic SQL-like queries\n",
    "- ACID transaction guarantees\n",
    "- Indexing for fast lookups\n",
    "- Data compression\n",
    "- Schema validation\n",
    "- Query optimization\n",
    "- Import/export functionality\n",
    "- Backup and recovery\n",
    "\n",
    "### 5.4. Distributed Version Control System\n",
    "Build a simplified version control system similar to Git.\n",
    "\n",
    "**Features:**\n",
    "- File change tracking\n",
    "- Commit history and branching\n",
    "- Merging and conflict resolution\n",
    "- Remote repository synchronization\n",
    "- Patch generation and application\n",
    "- Interactive staging area\n",
    "- Plugin architecture for extensions\n",
    "- Web interface for repository browsing\n",
    "\n",
    "### 5.5. Secure File Transfer Protocol\n",
    "Design and implement a secure protocol for transferring files between systems.\n",
    "\n",
    "**Features:**\n",
    "- End-to-end encryption\n",
    "- Authentication and authorization\n",
    "- Resume interrupted transfers\n",
    "- File integrity verification\n",
    "- Bandwidth management\n",
    "- Directory synchronization\n",
    "- Transfer logs and auditing\n",
    "- Cross-platform client implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416a0ac5-034d-4a56-8bf9-be25e2731a12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
